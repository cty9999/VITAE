<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>VITAE.model API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>VITAE.model</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Layer, Dense, BatchNormalization
import tensorflow_probability as tfp

 
class cdf_layer(Layer):
    def __init__(self):
        super(cdf_layer, self).__init__()
        
    @tf.function
    def call(self, x):
        return self.func(x)
        
    @tf.custom_gradient
    def func(self, x):
        dist = tfp.distributions.Normal(loc=0., scale=1., allow_nan_stats=False)
        f = dist.cdf(x)
        def grad(dy):
            gradient = dist.prob(x)
            return dy * gradient
        return f, grad
    

class Sampling(Layer):
    &#34;&#34;&#34;
    Sampling latent variable z by (z_mean, z_log_var).    
    Used in Encoder.
    &#34;&#34;&#34;
    @tf.function
    def call(self, z_mean, z_log_var):
        epsilon = tf.random.normal(shape = tf.shape(z_mean))
        z = z_mean + tf.exp(0.5 * z_log_var) * epsilon
        z = tf.clip_by_value(z, -1e6, 1e6)
        return z

class Encoder(Layer):
    &#39;&#39;&#39;
    Encoder, model q(z|x).
    &#39;&#39;&#39;
    def __init__(self, dimensions, dim_latent, name=&#39;encoder&#39;, **kwargs):
        &#39;&#39;&#39;
        Input:
          dimensions  - list of dimensions of layers in dense layers of
                       encoder expcept the latent layer.
          dim_latent  - dimension of latent layer.
        &#39;&#39;&#39;
        super(Encoder, self).__init__(name = name, **kwargs)
        self.dense_layers = [Dense(dim, activation = tf.nn.leaky_relu,
                                          name = &#39;encoder_%i&#39;%(i+1)) \
                             for (i, dim) in enumerate(dimensions)]
        self.batch_norm_layers = [BatchNormalization(center=False) \
                                    for _ in range(len((dimensions)))]
        self.batch_norm_layers.append(BatchNormalization(center=False))
        self.latent_mean = Dense(dim_latent, name = &#39;latent_mean&#39;)
        self.latent_log_var = Dense(dim_latent, name = &#39;latent_log_var&#39;)
        self.sampling = Sampling()
    
    @tf.function
    def call(self, x, L=1, is_training=True):
        &#39;&#39;&#39;
        Input :
            x           - input                     [batch_size, dim_origin]
        Output:
            z_mean      - mean of p(z|x)            [batch_size, dim_latent]
            z_log_var   - log of variance of p(z|x) [batch_size, dim_latent]
            z           - sampled z                 [batch_size, L, dim_latent]
        &#39;&#39;&#39;
        for dense, bn in zip(self.dense_layers, self.batch_norm_layers):
            x = dense(x)
            x = bn(x, training=is_training)
        z_mean = self.batch_norm_layers[-1](self.latent_mean(x), training=is_training)
        z_log_var = self.latent_log_var(x)
        _z_mean = tf.tile(tf.expand_dims(z_mean, 1), (1,L,1))
        _z_log_var = tf.tile(tf.expand_dims(z_log_var, 1), (1,L,1))
        z = self.sampling(_z_mean, _z_log_var)
        return z_mean, z_log_var, z


class Decoder(Layer):
    &#39;&#39;&#39;
    Decoder, model p(x|z).
    &#39;&#39;&#39;
    def __init__(self, dimensions, dim_origin, data_type = &#39;UMI&#39;, 
                name = &#39;decoder&#39;, **kwargs):
        &#39;&#39;&#39;
        Input:
            dimensions      - list of dimensions of layers in dense layers of
                                decoder expcept the output layer.
            dim_origin      - dimension of output layer.
            data_type       - &#39;UMI&#39;, &#39;non-UMI&#39; and &#39;Gaussian&#39;
        &#39;&#39;&#39;
        super(Decoder, self).__init__(name = name, **kwargs)
        self.data_type = data_type
        self.dense_layers = [Dense(dim, activation = tf.nn.leaky_relu,
                                          name = &#39;decoder_%i&#39;%(i+1)) \
                             for (i,dim) in enumerate(dimensions)]
        self.batch_norm_layers = [BatchNormalization(center=False) \
                                    for _ in range(len((dimensions)))]

        if data_type==&#39;Gaussian&#39;:
            self.nu_z = Dense(dim_origin, name = &#39;nu_z&#39;)
            # common variance
            self.log_tau = tf.Variable(tf.zeros([1, dim_origin]),
                                 constraint = lambda t: tf.clip_by_value(t,-30.,6.),
                                 name = &#34;log_tau&#34;)
        else:
            self.log_lambda_z = Dense(dim_origin, name = &#39;log_lambda_z&#39;)

            # dispersion parameter
            self.log_r = tf.Variable(tf.zeros([1, dim_origin]),
                                     constraint = lambda t: tf.clip_by_value(t,-30.,6.),
                                     name = &#34;log_r&#34;)
            
            if self.data_type == &#39;non-UMI&#39;:
                self.phi = Dense(dim_origin, activation = &#39;sigmoid&#39;, name = &#34;phi&#34;)
          
    @tf.function  
    def call(self, z, is_training=True):
        &#39;&#39;&#39;
        Input :
            z           - latent variables  [batch_size, L, dim_origin]
        Output:
            nu_z        - x_hat if Gaussian
            tau         - common variance if Gaussian
            lambda_z    - x_hat             [batch_size, L, dim_origin]
            r           - dispersion parameter
                                            [1,          L, dim_origin]
        &#39;&#39;&#39;
        for dense, bn in zip(self.dense_layers, self.batch_norm_layers):
            z = dense(z)
            z = bn(z, training=is_training)
        if self.data_type==&#39;Gaussian&#39;:
            nu_z = self.nu_z(z)
            tau = tf.exp(self.log_tau)
            return nu_z, tau
        else:
            lambda_z = tf.math.exp(
                tf.clip_by_value(self.log_lambda_z(z), -30., 6.)
                )
            r = tf.exp(self.log_r)
            if self.data_type==&#39;UMI&#39;:
                return lambda_z, r
            else:
                return lambda_z, r, self.phi(z)


class LatentSpace(Layer):
    &#39;&#39;&#39;
    Layer for the Latent Space.
    It contains parameters related to model assumptions.
    &#39;&#39;&#39;
    def __init__(self, n_clusters, dim_latent, M = 50, name = &#39;LatentSpace&#39;, **kwargs):
        &#39;&#39;&#39;
        Input:
          dim_latent   - dimension of latent layer.
          dim_origin - dimension of output layer.
          M            - number of samples for w.
        &#39;&#39;&#39;
        super(LatentSpace, self).__init__(name=name, **kwargs)
        self.dim_latent = dim_latent
        self.n_clusters = n_clusters
        self.n_states = int(n_clusters*(n_clusters+1)/2)

        # nonzero indexes
        # A = [0,0,...,0  , 1,1,...,1,   ...]
        # B = [0,1,...,k-1, 1,2,...,k-1, ...]
        self.A, self.B = np.nonzero(np.triu(np.ones(n_clusters)))
        self.A = tf.convert_to_tensor(self.A, tf.int32)
        self.B = tf.convert_to_tensor(self.B, tf.int32)
        self.clusters_ind = tf.boolean_mask(
            tf.range(0,self.n_states,1), self.A==self.B)

        # Uniform random variable
        self.M = tf.convert_to_tensor(M, tf.int32)
        self.w =  tf.convert_to_tensor(
            np.resize(np.arange(0, M)/M, (1, M)), tf.float32)

        # [pi_1, ... , pi_K] in R^(n_states)
        self.pi = tf.Variable(tf.ones([1, self.n_states]) / self.n_states,
                                name = &#39;pi&#39;)
        
        # [mu_1, ... , mu_K] in R^(dim_latent * n_clusters)
        self.mu = tf.Variable(tf.random.uniform([self.dim_latent, self.n_clusters],
                                                minval = -1, maxval = 1),
                                name = &#39;mu&#39;)
        self.cdf_layer = cdf_layer()       
        
    def initialize(self, mu, pi):
        # Initialize parameters of the latent space
        if mu is not None:
            self.mu.assign(mu)
        if pi is not None:
            self.pi.assign(pi)

    def normalize(self):
        self.pi = tf.nn.softmax(self.pi)

    @tf.function
    def _get_normal_params(self, z):
        batch_size = tf.shape(z)[0]
        L = tf.shape(z)[1]
        
        # [batch_size, L, n_states]
        temp_pi = tf.tile(
            tf.expand_dims(tf.nn.softmax(self.pi), 1),
            (batch_size,L,1))
                        
        # [batch_size, L, d, n_states]
        a1 = tf.expand_dims(tf.expand_dims(
            tf.gather(self.mu, self.B, axis=1) - tf.gather(self.mu, self.A, axis=1), 0), 0)
        a2 = tf.expand_dims(z,-1) - \
            tf.expand_dims(tf.expand_dims(
            tf.gather(self.mu, self.B, axis=1), 0), 0)
            
        # [batch_size, L, n_states]
        _inv_sig = tf.reduce_sum(a1 * a1, axis=2)
        _mu = - tf.reduce_sum(a1 * a2, axis=2)*tf.math.reciprocal_no_nan(_inv_sig)
        _t = - tf.reduce_sum(a2 * a2, axis=2) + _mu**2*_inv_sig
        return temp_pi, a2, _inv_sig, _mu, _t
    
    @tf.function
    def _get_pz(self, temp_pi, _inv_sig, a2, log_p_z_c_L):
        # [batch_size, L, n_states]
        log_p_zc_L = - 0.5 * self.dim_latent * tf.math.log(2 * np.pi) + \
            tf.math.log(temp_pi+1e-12) + \
            tf.where(_inv_sig==0, 
                    - 0.5 * tf.reduce_sum(a2**2, axis=2), 
                    log_p_z_c_L)
        
        # [batch_size, L, 1]
        log_p_z_L = tf.reduce_logsumexp(log_p_zc_L, axis=-1, keepdims=True)
        
        # [1, ]
        log_p_z = tf.reduce_mean(log_p_z_L)
        return log_p_zc_L, log_p_z_L, log_p_z
    
    @tf.function
    def _get_posterior_c(self, log_p_zc_L, log_p_z_L):
        L = tf.shape(log_p_z_L)[1]

        # log_p_c_x     -   predicted probability distribution
        # [batch_size, n_states]
        log_p_c_x = tf.reduce_logsumexp(
                        log_p_zc_L - log_p_z_L,
                    axis=1) - tf.math.log(tf.cast(L, tf.float32))
        return log_p_c_x

    @tf.function
    def _get_inference(self, z, log_p_zc_L, log_p_z_L):
        batch_size = tf.shape(z)[0]
        L = tf.shape(z)[1]
        
        # [batch_size, L, dim_latent, n_states, M]
        temp_Z = tf.tile(tf.expand_dims(tf.expand_dims(z,-1), -1),
                    (1,1,1,self.n_states,self.M))
        temp_mu = tf.tile(
                        tf.expand_dims(tf.expand_dims(
                            tf.gather(self.mu, self.A, axis=1),0),-1),
                        (batch_size,1,1,self.M)) * self.w + \
                tf.tile(
                        tf.expand_dims(tf.expand_dims(
                            tf.gather(self.mu, self.B, axis=1),0),-1),
                        (batch_size,1,1,self.M)) * (1-self.w)
        temp_mu = tf.tile(tf.expand_dims(temp_mu, 1), (1,L,1,1,1))
            
        # [batch_size, L, n_states, M]
        temp_pi = tf.tile(tf.expand_dims(
                        tf.expand_dims(tf.nn.softmax(self.pi), -1), 1),
                        (batch_size,L,1,self.M))
        
        # [batch_size, L, n_states, M]
        log_p_zc_w = - 0.5 * self.dim_latent * tf.math.log(2 * np.pi) + \
                        tf.math.log(temp_pi+1e-12) - \
                        tf.reduce_sum(tf.math.square(temp_Z - temp_mu), 2)/2  # this omits a term -logM for avoiding numerical issue
                        
        # [batch_size, L]
        log_p_z_L = tf.expand_dims(tf.reduce_logsumexp(log_p_zc_w, axis=[2,3]), -1) # this omits a term -logM for avoiding numerical issue
                    
        # [batch_size, n_states, M]
        p_wc_x = tf.exp(tf.reduce_logsumexp(
                    log_p_zc_w -
                    tf.expand_dims(log_p_z_L, -1),
                    1) - tf.math.log(tf.cast(L, tf.float32)))
                    
        # [batch_size, n_states, n_clusters, M]
        _w = tf.tile(tf.expand_dims(
                tf.tile(tf.expand_dims(
                    tf.one_hot(self.A, self.n_clusters),
                    -1), (1,1,self.M)) * self.w +
                tf.tile(tf.expand_dims(
                    tf.one_hot(self.B, self.n_clusters),
                    -1), (1,1,self.M)) * (1-self.w), 0), (batch_size,1,1,1))
                    
        # [batch_size, n_clusters]
        w_tilde = tf.reduce_sum(
            _w  * \
            tf.tile(tf.expand_dims(p_wc_x, 2), (1,1,self.n_clusters,1)),
            (1,3))
            
        var_w_tilde = tf.reduce_sum(
            tf.math.square(_w)  *
            tf.tile(tf.expand_dims(p_wc_x, 2), (1,1,self.n_clusters,1)),
            (1,3)) - tf.square(w_tilde)    
        
        _wtilde = tf.expand_dims(tf.expand_dims(w_tilde, 1), -1)
        D_JS = tf.reduce_sum(
            tf.math.sqrt(
                0.5 * tf.reduce_mean(
                    _w * tf.math.log(
                        _w/(0.5 * (_w + _wtilde) + 1e-12) + 1e-12) +
                    _wtilde * tf.math.log(
                        _wtilde/(0.5 * (_w + _wtilde) + 1e-12) + 1e-12),
                    axis=2)) * \
            p_wc_x, (1,2)) / tf.cast(self.M, tf.float32)
        return w_tilde, var_w_tilde, D_JS
    
    def get_pz(self, z):
        temp_pi, a2, _inv_sig, _mu, _t = self._get_normal_params(z)
        
        log_p_z_c_L =  0.5 * (tf.math.log(2 * np.pi) - \
                        tf.math.log(_inv_sig+1e-12) + \
                        _t
                        ) + \
                        tf.math.log(self.cdf_layer((1-_mu)*tf.math.sqrt(_inv_sig+1e-12)) - 
                                    self.cdf_layer(-_mu*tf.math.sqrt(_inv_sig+1e-12)) + 1e-12)
        
        log_p_zc_L, log_p_z_L, log_p_z = self._get_pz(temp_pi, _inv_sig, a2, log_p_z_c_L)
        return log_p_zc_L, log_p_z_L, log_p_z

    def call(self, z, inference=False):
        &#39;&#39;&#39;
        Input :
                z       - latent variables outputed by the encoder
                          [batch_size, L, dim_latent]
        Output:       
            inference = True:     
                log_p_z - MC samples for log p(z)=log sum_{c}p(z|c)*p(c)
                          [batch_size, ]
            inference = False:
                res     - results contains estimations for 
                            p(c|x), E(w|x), Var(w|x), E(w|x,c), Var(w|x,c), 
                            c, E(w_tilde), Var(w_tilde), D_JS
        &#39;&#39;&#39;               
        log_p_zc_L, log_p_z_L, log_p_z = self.get_pz(z)

        if not inference:
            return log_p_z
        else:
            log_p_c_x = self._get_posterior_c(log_p_zc_L, log_p_z_L)
            w_tilde, var_w_tilde, D_JS = self._get_inference(z, log_p_zc_L, log_p_z_L)
            
            res = {}
            res[&#39;p_c_x&#39;] = tf.exp(log_p_c_x).numpy()
            res[&#39;w_tilde&#39;] = w_tilde.numpy()
            res[&#39;var_w_tilde&#39;] = var_w_tilde.numpy()
            res[&#39;D_JS&#39;] = D_JS.numpy()
            return res

    def get_posterior_c(self, z):
        log_p_zc_L, log_p_z_L, _ = self.get_pz(z)
        log_p_c_x = self._get_posterior_c(log_p_zc_L, log_p_z_L)
        p_c_x = tf.exp(log_p_c_x).numpy()
        return p_c_x

    def get_proj_z(self, c):
        &#39;&#39;&#39;
        Args:
            c - Numpy array of indexes [1,*]
        &#39;&#39;&#39;
        proj_c = np.tile(c, (self.M,1)).T.flatten()
        proj_z_M = tf.transpose(
                        tf.gather(self.mu, tf.gather(self.A, proj_c), axis=1) * 
                        tf.tile(self.w, (1,len(c))) + 
                        tf.gather(self.mu, tf.gather(self.B, proj_c), axis=1) * 
                        (1-tf.tile(self.w, (1,len(c))))
                    )
        return proj_c, proj_z_M.numpy()
            
            
class VariationalAutoEncoder(tf.keras.Model):
    &#34;&#34;&#34;
    Combines the encoder, decoder and LatentSpace into an end-to-end model for training.
    &#34;&#34;&#34;
    def __init__(self, dim_origin, dimensions, dim_latent,
                 data_type = &#39;UMI&#39;, has_cov=False,
                 name = &#39;autoencoder&#39;, **kwargs):
        &#39;&#39;&#39;
        Args:
            n_clusters      -   Number of clusters.
            dim_origin      -   Dim of input.
            dimensions      -   List of dimensions of layers of the encoder. Assume
                               symmetric network sturcture of encoder and decoder.
            dim_latent      -   Dimension of latent layer.
            data_type       -   Type of count data.
                              &#39;UMI&#39; for negative binomial loss;
                              &#39;non-UMI&#39; for zero-inflated negative binomial loss.
            has_cov         - has covariate or not
        &#39;&#39;&#39;
        super(VariationalAutoEncoder, self).__init__(name = name, **kwargs)
        self.data_type = data_type
        self.dim_origin = dim_origin
        self.dim_latent = dim_latent
        self.encoder = Encoder(dimensions, dim_latent)
        self.decoder = Decoder(dimensions[::-1], dim_origin, data_type, data_type)        
        self.has_cov = has_cov
        
    def init_latent_space(self, n_clusters, mu, pi=None):
        self.n_clusters = n_clusters
        self.latent_space = LatentSpace(self.n_clusters, self.dim_latent)
        self.latent_space.initialize(mu, pi)

    def call(self, x_normalized, c_score, x = None, scale_factor = 1,
             pre_train = False, L=1, alpha=0.0):
        # Feed forward through encoder, LatentSpace layer and decoder.
        if not pre_train and self.latent_space is None:
            raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
                    
        x_normalized = tf.concat([x_normalized, c_score], -1) if self.has_cov else x_normalized
        _, z_log_var, z = self.encoder(x_normalized, L)
                
        z_in = tf.concat([z, tf.tile(tf.expand_dims(c_score,1), (1,L,1))], -1) if self.has_cov else z
        
        x = tf.tile(tf.expand_dims(x, 1), (1,L,1))
        reconstruction_z_loss = self.get_reconstruction_loss(x, z_in, scale_factor, L)
        
        if self.has_cov and alpha&gt;0.0:
            zero_in = tf.concat([tf.zeros([z.shape[0],1,z.shape[2]]), tf.tile(tf.expand_dims(c_score,1), (1,1,1))], -1)
            reconstruction_zero_loss = self.get_reconstruction_loss(x, zero_in, scale_factor, 1)
            reconstruction_z_loss = (1-alpha)*reconstruction_z_loss + alpha*reconstruction_zero_loss
        
        self.add_loss(reconstruction_z_loss)

        if not pre_train:        
            log_p_z = self.latent_space(z, inference=False)

            # - E_q[log p(z)]
            self.add_loss(- log_p_z)

            # - Eq[log q(z|x)]
            E_qzx = - tf.reduce_mean(
                            0.5 * self.dim_latent *
                            (tf.math.log(2 * np.pi) + 1) +
                            0.5 * tf.reduce_sum(z_log_var, axis=-1)
                            )
            self.add_loss(E_qzx)
        return self.losses
    
    @tf.function
    def get_reconstruction_loss(self, x, z_in, scale_factor, L):
        if self.data_type==&#39;Gaussian&#39;:
            # Gaussian Log-Likelihood Loss function
            nu_z, tau = self.decoder(z_in)
            neg_E_Gaus = 0.5 * tf.math.log(tau + 1e-12) + 0.5 * tf.math.square(x - nu_z) / tau
            neg_E_Gaus = tf.reduce_mean(tf.reduce_sum(neg_E_Gaus, axis=-1))
            
            return neg_E_Gaus
        else:
            if self.data_type == &#39;UMI&#39;:
                x_hat, r = self.decoder(z_in)
            else:
                x_hat, r, phi = self.decoder(z_in)

            x_hat = x_hat*tf.expand_dims(scale_factor, -1)

            # Negative Log-Likelihood Loss function

            # Ref for NB &amp; ZINB loss functions:
            # https://github.com/gokceneraslan/neuralnet_countmodels/blob/master/Count%20models%20with%20neuralnets.ipynb
            # Negative Binomial loss

            neg_E_nb = tf.math.lgamma(r) + tf.math.lgamma(x+1.0) \
                        - tf.math.lgamma(x+r) + \
                        (r+x) * tf.math.log(1.0 + (x_hat/r)) + \
                        x * (tf.math.log(r) - tf.math.log(x_hat+1e-12))
            
            if self.data_type == &#39;non-UMI&#39;:
                # Zero-Inflated Negative Binomial loss
                nb_case = neg_E_nb - tf.math.log(1.0-phi+1e-12)
                zero_case = - tf.math.log(phi + (1.0-phi) *
                                     tf.pow(r/(r + x_hat + 1e-12), r) + 1e-12)
                neg_E_nb = tf.where(tf.less(x, 1e-8), zero_case, nb_case)

            neg_E_nb =  tf.reduce_mean(tf.reduce_sum(neg_E_nb, axis=-1))
            
            return neg_E_nb
    
    def get_z(self, x_normalized, c_score):        
        x_normalized = x_normalized if (not self.has_cov or c_score is None) else tf.concat([x_normalized, c_score], -1)
        z_mean, _, _ = self.encoder(x_normalized, 1, False)
        return z_mean.numpy()
    
    def get_proj_z(self, c):
        &#39;&#39;&#39;
        Args:
            c - List of indexes of edges
        &#39;&#39;&#39;
        return self.latent_space.get_proj_z(c)

    def get_pc_x(self, test_dataset):
        if self.latent_space is None:
            raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
        
        pi_norm = tf.nn.softmax(self.latent_space.pi).numpy()
        p_c_x = []
        for x,c_score in test_dataset:
            x = tf.concat([x, c_score], -1) if self.has_cov else x
            _, _, z = self.encoder(x, 1, False)
            _p_c_x = self.latent_space.get_posterior_c(z)            
            p_c_x.append(_p_c_x)
        p_c_x = np.concatenate(p_c_x)         
        return pi_norm, p_c_x

    def inference(self, test_dataset, L=1):
        if self.latent_space is None:
            raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
            
        pi_norm = tf.nn.softmax(self.latent_space.pi).numpy()
        mu = self.latent_space.mu.numpy()
        z_mean = []
        p_c_x = []
        w_tilde = []
        var_w_tilde = []
        D_JS = []
        for x,c_score in test_dataset:
            x = tf.concat([x, c_score], -1) if self.has_cov else x
            _z_mean, _, z = self.encoder(x, L, False)
            res = self.latent_space(z, inference=True)
            
            z_mean.append(_z_mean.numpy())
            p_c_x.append(res[&#39;p_c_x&#39;])            
            w_tilde.append(res[&#39;w_tilde&#39;])
            var_w_tilde.append(res[&#39;var_w_tilde&#39;])
            D_JS.append(res[&#39;D_JS&#39;])
        
        D_JS = np.concatenate(D_JS)
        z_mean = np.concatenate(z_mean)
        p_c_x = np.concatenate(p_c_x)
        w_tilde = np.concatenate(w_tilde)
        var_w_tilde = np.concatenate(var_w_tilde)
        return pi_norm, mu, p_c_x, w_tilde, var_w_tilde, D_JS, z_mean</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="VITAE.model.cdf_layer"><code class="flex name class">
<span>class <span class="ident">cdf_layer</span></span>
</code></dt>
<dd>
<div class="desc"><p>This is the class from which all layers inherit.</p>
<p>A layer is a callable object that takes as input one or more tensors and
that outputs one or more tensors. It involves <em>computation</em>, defined
in the <code>call()</code> method, and a <em>state</em> (weight variables), defined
either in the constructor <code>__init__()</code> or in the <code>build()</code> method.</p>
<p>Users will just instantiate a layer and then treat it as a callable.</p>
<h2 id="arguments">Arguments</h2>
<p>trainable: Boolean, whether the layer's variables should be trainable.
name: String name of the layer.
dtype: The dtype of the layer's computations and weights (default of
<code>None</code> means use <code>tf.keras.backend.floatx</code> in TensorFlow 2, or the type
of the first input in TensorFlow 1).
dynamic: Set this to <code>True</code> if your layer should only be run eagerly, and
should not be used to generate a static computation graph.
This would be the case for a Tree-RNN or a recursive network,
for example, or generally for any layer that manipulates tensors
using Python control flow. If <code>False</code>, we assume that the layer can
safely be used to generate a static computation graph.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>The name of the layer (string).</dd>
<dt><strong><code>dtype</code></strong></dt>
<dd>The dtype of the layer's computations and weights. If mixed
precision is used with a <code>tf.keras.mixed_precision.experimental.Policy</code>,
this is instead just the dtype of the layer's weights, as the computations
are done in a different dtype.</dd>
<dt><strong><code>trainable_weights</code></strong></dt>
<dd>List of variables to be included in backprop.</dd>
<dt><strong><code>non_trainable_weights</code></strong></dt>
<dd>List of variables that should not be
included in backprop.</dd>
<dt><strong><code>weights</code></strong></dt>
<dd>The concatenation of the lists trainable_weights and
non_trainable_weights (in this order).</dd>
<dt><strong><code>trainable</code></strong></dt>
<dd>Whether the layer should be trained (boolean), i.e. whether
its potentially-trainable weights should be returned as part of
<code>layer.trainable_weights</code>.</dd>
<dt><strong><code>input_spec</code></strong></dt>
<dd>Optional (list of) <code>InputSpec</code> object(s) specifying the
constraints on inputs that can be accepted by the layer.</dd>
</dl>
<p>We recommend that descendants of <code>Layer</code> implement the following methods:</p>
<ul>
<li><code>__init__()</code>: Defines custom layer attributes, and creates layer state
variables that do not depend on input shapes, using <code>add_weight()</code>.</li>
<li><code>build(self, input_shape)</code>: This method can be used to create weights that
depend on the shape(s) of the input(s), using <code>add_weight()</code>. <code>__call__()</code>
will automatically build the layer (if it has not been built yet) by
calling <code>build()</code>.</li>
<li><code>call(self, *args, **kwargs)</code>: Called in <code>__call__</code> after making sure
<code>build()</code> has been called. <code>call()</code> performs the logic of applying the
layer to the input tensors (which should be passed in as argument).
Two reserved keyword arguments you can optionally use in <code>call()</code> are:<ul>
<li><code>training</code> (boolean, whether the call is in
inference mode or training mode)</li>
<li><code>mask</code> (boolean tensor encoding masked timesteps in the input, used
in RNN layers)</li>
</ul>
</li>
<li><code>get_config(self)</code>: Returns a dictionary containing the configuration used
to initialize this layer. If the keys differ from the arguments
in <code>__init__</code>, then override <code>from_config(self)</code> as well.
This method is used when saving
the layer or a model that contains this layer.</li>
</ul>
<p>Examples:</p>
<p>Here's a basic example: a layer with two variables, <code>w</code> and <code>b</code>,
that returns <code>y = w . x + b</code>.
It shows how to implement <code>build()</code> and <code>call()</code>.
Variables set as attributes of a layer are tracked as weights
of the layers (in <code>layer.weights</code>).</p>
<pre><code class="language-python">class SimpleDense(Layer):

  def __init__(self, units=32):
      super(SimpleDense, self).__init__()
      self.units = units

  def build(self, input_shape):  # Create the state of the layer (weights)
    w_init = tf.random_normal_initializer()
    self.w = tf.Variable(
        initial_value=w_init(shape=(input_shape[-1], self.units),
                             dtype='float32'),
        trainable=True)
    b_init = tf.zeros_initializer()
    self.b = tf.Variable(
        initial_value=b_init(shape=(self.units,), dtype='float32'),
        trainable=True)

  def call(self, inputs):  # Defines the computation from inputs to outputs
      return tf.matmul(inputs, self.w) + self.b

# Instantiates the layer.
linear_layer = SimpleDense(4)

# This will also call `build(input_shape)` and create the weights.
y = linear_layer(tf.ones((2, 2)))
assert len(linear_layer.weights) == 2

# These weights are trainable, so they're listed in `trainable_weights`:
assert len(linear_layer.trainable_weights) == 2
</code></pre>
<p>Note that the method <code>add_weight()</code> offers a shortcut to create weights:</p>
<pre><code class="language-python">class SimpleDense(Layer):

  def __init__(self, units=32):
      super(SimpleDense, self).__init__()
      self.units = units

  def build(self, input_shape):
      self.w = self.add_weight(shape=(input_shape[-1], self.units),
                               initializer='random_normal',
                               trainable=True)
      self.b = self.add_weight(shape=(self.units,),
                               initializer='random_normal',
                               trainable=True)

  def call(self, inputs):
      return tf.matmul(inputs, self.w) + self.b
</code></pre>
<p>Besides trainable weights, updated via backpropagation during training,
layers can also have non-trainable weights. These weights are meant to
be updated manually during <code>call()</code>. Here's a example layer that computes
the running sum of its inputs:</p>
<pre><code class="language-python">class ComputeSum(Layer):

  def __init__(self, input_dim):
      super(ComputeSum, self).__init__()
      # Create a non-trainable weight.
      self.total = tf.Variable(initial_value=tf.zeros((input_dim,)),
                               trainable=False)

  def call(self, inputs):
      self.total.assign_add(tf.reduce_sum(inputs, axis=0))
      return self.total

my_sum = ComputeSum(2)
x = tf.ones((2, 2))

y = my_sum(x)
print(y.numpy())  # [2. 2.]

y = my_sum(x)
print(y.numpy())  # [4. 4.]

assert my_sum.weights == [my_sum.total]
assert my_sum.non_trainable_weights == [my_sum.total]
assert my_sum.trainable_weights == []
</code></pre>
<p>For more information about creating layers, see the guide
<a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Writing custom layers and models with Keras</a></p>
<p>About the layer's <code>dtype</code> attribute:</p>
<p>Each layer has a dtype, which is typically the dtype of the layer's
computations and variables. A layer's dtype can be queried via the
<code>Layer.dtype</code> property. The dtype is specified with the <code>dtype</code> constructor
argument. In TensorFlow 2, the dtype defaults to <code>tf.keras.backend.floatx()</code>
if no dtype is passed. <code>floatx()</code> itself defaults to "float32". Additionally,
layers will cast their inputs to the layer's dtype in TensorFlow 2. When mixed
precision is used, layers may have different computation and variable dtypes.
See <code>tf.keras.mixed_precision.experimental.Policy</code> for details on layer
dtypes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class cdf_layer(Layer):
    def __init__(self):
        super(cdf_layer, self).__init__()
        
    @tf.function
    def call(self, x):
        return self.func(x)
        
    @tf.custom_gradient
    def func(self, x):
        dist = tfp.distributions.Normal(loc=0., scale=1., allow_nan_stats=False)
        f = dist.cdf(x)
        def grad(dy):
            gradient = dist.prob(x)
            return dy * gradient
        return f, grad</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="VITAE.model.cdf_layer.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.function
def call(self, x):
    return self.func(x)</code></pre>
</details>
</dd>
<dt id="VITAE.model.cdf_layer.func"><code class="name flex">
<span>def <span class="ident">func</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.custom_gradient
def func(self, x):
    dist = tfp.distributions.Normal(loc=0., scale=1., allow_nan_stats=False)
    f = dist.cdf(x)
    def grad(dy):
        gradient = dist.prob(x)
        return dy * gradient
    return f, grad</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="VITAE.model.Sampling"><code class="flex name class">
<span>class <span class="ident">Sampling</span></span>
<span>(</span><span>trainable=True, name=None, dtype=None, dynamic=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Sampling latent variable z by (z_mean, z_log_var).
<br>
Used in Encoder.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sampling(Layer):
    &#34;&#34;&#34;
    Sampling latent variable z by (z_mean, z_log_var).    
    Used in Encoder.
    &#34;&#34;&#34;
    @tf.function
    def call(self, z_mean, z_log_var):
        epsilon = tf.random.normal(shape = tf.shape(z_mean))
        z = z_mean + tf.exp(0.5 * z_log_var) * epsilon
        z = tf.clip_by_value(z, -1e6, 1e6)
        return z</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="VITAE.model.Sampling.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, z_mean, z_log_var)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.function
def call(self, z_mean, z_log_var):
    epsilon = tf.random.normal(shape = tf.shape(z_mean))
    z = z_mean + tf.exp(0.5 * z_log_var) * epsilon
    z = tf.clip_by_value(z, -1e6, 1e6)
    return z</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="VITAE.model.Encoder"><code class="flex name class">
<span>class <span class="ident">Encoder</span></span>
<span>(</span><span>dimensions, dim_latent, name='encoder', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Encoder, model q(z|x).</p>
<h2 id="input">Input</h2>
<p>dimensions
- list of dimensions of layers in dense layers of
encoder expcept the latent layer.
dim_latent
- dimension of latent layer.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Encoder(Layer):
    &#39;&#39;&#39;
    Encoder, model q(z|x).
    &#39;&#39;&#39;
    def __init__(self, dimensions, dim_latent, name=&#39;encoder&#39;, **kwargs):
        &#39;&#39;&#39;
        Input:
          dimensions  - list of dimensions of layers in dense layers of
                       encoder expcept the latent layer.
          dim_latent  - dimension of latent layer.
        &#39;&#39;&#39;
        super(Encoder, self).__init__(name = name, **kwargs)
        self.dense_layers = [Dense(dim, activation = tf.nn.leaky_relu,
                                          name = &#39;encoder_%i&#39;%(i+1)) \
                             for (i, dim) in enumerate(dimensions)]
        self.batch_norm_layers = [BatchNormalization(center=False) \
                                    for _ in range(len((dimensions)))]
        self.batch_norm_layers.append(BatchNormalization(center=False))
        self.latent_mean = Dense(dim_latent, name = &#39;latent_mean&#39;)
        self.latent_log_var = Dense(dim_latent, name = &#39;latent_log_var&#39;)
        self.sampling = Sampling()
    
    @tf.function
    def call(self, x, L=1, is_training=True):
        &#39;&#39;&#39;
        Input :
            x           - input                     [batch_size, dim_origin]
        Output:
            z_mean      - mean of p(z|x)            [batch_size, dim_latent]
            z_log_var   - log of variance of p(z|x) [batch_size, dim_latent]
            z           - sampled z                 [batch_size, L, dim_latent]
        &#39;&#39;&#39;
        for dense, bn in zip(self.dense_layers, self.batch_norm_layers):
            x = dense(x)
            x = bn(x, training=is_training)
        z_mean = self.batch_norm_layers[-1](self.latent_mean(x), training=is_training)
        z_log_var = self.latent_log_var(x)
        _z_mean = tf.tile(tf.expand_dims(z_mean, 1), (1,L,1))
        _z_log_var = tf.tile(tf.expand_dims(z_log_var, 1), (1,L,1))
        z = self.sampling(_z_mean, _z_log_var)
        return z_mean, z_log_var, z</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="VITAE.model.Encoder.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, x, L=1, is_training=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Input :
x
- input
[batch_size, dim_origin]</p>
<h2 id="output">Output</h2>
<p>z_mean
- mean of p(z|x)
[batch_size, dim_latent]
z_log_var
- log of variance of p(z|x) [batch_size, dim_latent]
z
- sampled z
[batch_size, L, dim_latent]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.function
def call(self, x, L=1, is_training=True):
    &#39;&#39;&#39;
    Input :
        x           - input                     [batch_size, dim_origin]
    Output:
        z_mean      - mean of p(z|x)            [batch_size, dim_latent]
        z_log_var   - log of variance of p(z|x) [batch_size, dim_latent]
        z           - sampled z                 [batch_size, L, dim_latent]
    &#39;&#39;&#39;
    for dense, bn in zip(self.dense_layers, self.batch_norm_layers):
        x = dense(x)
        x = bn(x, training=is_training)
    z_mean = self.batch_norm_layers[-1](self.latent_mean(x), training=is_training)
    z_log_var = self.latent_log_var(x)
    _z_mean = tf.tile(tf.expand_dims(z_mean, 1), (1,L,1))
    _z_log_var = tf.tile(tf.expand_dims(z_log_var, 1), (1,L,1))
    z = self.sampling(_z_mean, _z_log_var)
    return z_mean, z_log_var, z</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="VITAE.model.Decoder"><code class="flex name class">
<span>class <span class="ident">Decoder</span></span>
<span>(</span><span>dimensions, dim_origin, data_type='UMI', name='decoder', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Decoder, model p(x|z).</p>
<h2 id="input">Input</h2>
<p>dimensions
- list of dimensions of layers in dense layers of
decoder expcept the output layer.
dim_origin
- dimension of output layer.
data_type
- 'UMI', 'non-UMI' and 'Gaussian'</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Decoder(Layer):
    &#39;&#39;&#39;
    Decoder, model p(x|z).
    &#39;&#39;&#39;
    def __init__(self, dimensions, dim_origin, data_type = &#39;UMI&#39;, 
                name = &#39;decoder&#39;, **kwargs):
        &#39;&#39;&#39;
        Input:
            dimensions      - list of dimensions of layers in dense layers of
                                decoder expcept the output layer.
            dim_origin      - dimension of output layer.
            data_type       - &#39;UMI&#39;, &#39;non-UMI&#39; and &#39;Gaussian&#39;
        &#39;&#39;&#39;
        super(Decoder, self).__init__(name = name, **kwargs)
        self.data_type = data_type
        self.dense_layers = [Dense(dim, activation = tf.nn.leaky_relu,
                                          name = &#39;decoder_%i&#39;%(i+1)) \
                             for (i,dim) in enumerate(dimensions)]
        self.batch_norm_layers = [BatchNormalization(center=False) \
                                    for _ in range(len((dimensions)))]

        if data_type==&#39;Gaussian&#39;:
            self.nu_z = Dense(dim_origin, name = &#39;nu_z&#39;)
            # common variance
            self.log_tau = tf.Variable(tf.zeros([1, dim_origin]),
                                 constraint = lambda t: tf.clip_by_value(t,-30.,6.),
                                 name = &#34;log_tau&#34;)
        else:
            self.log_lambda_z = Dense(dim_origin, name = &#39;log_lambda_z&#39;)

            # dispersion parameter
            self.log_r = tf.Variable(tf.zeros([1, dim_origin]),
                                     constraint = lambda t: tf.clip_by_value(t,-30.,6.),
                                     name = &#34;log_r&#34;)
            
            if self.data_type == &#39;non-UMI&#39;:
                self.phi = Dense(dim_origin, activation = &#39;sigmoid&#39;, name = &#34;phi&#34;)
          
    @tf.function  
    def call(self, z, is_training=True):
        &#39;&#39;&#39;
        Input :
            z           - latent variables  [batch_size, L, dim_origin]
        Output:
            nu_z        - x_hat if Gaussian
            tau         - common variance if Gaussian
            lambda_z    - x_hat             [batch_size, L, dim_origin]
            r           - dispersion parameter
                                            [1,          L, dim_origin]
        &#39;&#39;&#39;
        for dense, bn in zip(self.dense_layers, self.batch_norm_layers):
            z = dense(z)
            z = bn(z, training=is_training)
        if self.data_type==&#39;Gaussian&#39;:
            nu_z = self.nu_z(z)
            tau = tf.exp(self.log_tau)
            return nu_z, tau
        else:
            lambda_z = tf.math.exp(
                tf.clip_by_value(self.log_lambda_z(z), -30., 6.)
                )
            r = tf.exp(self.log_r)
            if self.data_type==&#39;UMI&#39;:
                return lambda_z, r
            else:
                return lambda_z, r, self.phi(z)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="VITAE.model.Decoder.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, z, is_training=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Input :
z
- latent variables
[batch_size, L, dim_origin]</p>
<h2 id="output">Output</h2>
<p>nu_z
- x_hat if Gaussian
tau
- common variance if Gaussian
lambda_z
- x_hat
[batch_size, L, dim_origin]
r
- dispersion parameter
[1,
L, dim_origin]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.function  
def call(self, z, is_training=True):
    &#39;&#39;&#39;
    Input :
        z           - latent variables  [batch_size, L, dim_origin]
    Output:
        nu_z        - x_hat if Gaussian
        tau         - common variance if Gaussian
        lambda_z    - x_hat             [batch_size, L, dim_origin]
        r           - dispersion parameter
                                        [1,          L, dim_origin]
    &#39;&#39;&#39;
    for dense, bn in zip(self.dense_layers, self.batch_norm_layers):
        z = dense(z)
        z = bn(z, training=is_training)
    if self.data_type==&#39;Gaussian&#39;:
        nu_z = self.nu_z(z)
        tau = tf.exp(self.log_tau)
        return nu_z, tau
    else:
        lambda_z = tf.math.exp(
            tf.clip_by_value(self.log_lambda_z(z), -30., 6.)
            )
        r = tf.exp(self.log_r)
        if self.data_type==&#39;UMI&#39;:
            return lambda_z, r
        else:
            return lambda_z, r, self.phi(z)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="VITAE.model.LatentSpace"><code class="flex name class">
<span>class <span class="ident">LatentSpace</span></span>
<span>(</span><span>n_clusters, dim_latent, M=50, name='LatentSpace', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Layer for the Latent Space.
It contains parameters related to model assumptions.</p>
<h2 id="input">Input</h2>
<p>dim_latent
- dimension of latent layer.
dim_origin - dimension of output layer.
M
- number of samples for w.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LatentSpace(Layer):
    &#39;&#39;&#39;
    Layer for the Latent Space.
    It contains parameters related to model assumptions.
    &#39;&#39;&#39;
    def __init__(self, n_clusters, dim_latent, M = 50, name = &#39;LatentSpace&#39;, **kwargs):
        &#39;&#39;&#39;
        Input:
          dim_latent   - dimension of latent layer.
          dim_origin - dimension of output layer.
          M            - number of samples for w.
        &#39;&#39;&#39;
        super(LatentSpace, self).__init__(name=name, **kwargs)
        self.dim_latent = dim_latent
        self.n_clusters = n_clusters
        self.n_states = int(n_clusters*(n_clusters+1)/2)

        # nonzero indexes
        # A = [0,0,...,0  , 1,1,...,1,   ...]
        # B = [0,1,...,k-1, 1,2,...,k-1, ...]
        self.A, self.B = np.nonzero(np.triu(np.ones(n_clusters)))
        self.A = tf.convert_to_tensor(self.A, tf.int32)
        self.B = tf.convert_to_tensor(self.B, tf.int32)
        self.clusters_ind = tf.boolean_mask(
            tf.range(0,self.n_states,1), self.A==self.B)

        # Uniform random variable
        self.M = tf.convert_to_tensor(M, tf.int32)
        self.w =  tf.convert_to_tensor(
            np.resize(np.arange(0, M)/M, (1, M)), tf.float32)

        # [pi_1, ... , pi_K] in R^(n_states)
        self.pi = tf.Variable(tf.ones([1, self.n_states]) / self.n_states,
                                name = &#39;pi&#39;)
        
        # [mu_1, ... , mu_K] in R^(dim_latent * n_clusters)
        self.mu = tf.Variable(tf.random.uniform([self.dim_latent, self.n_clusters],
                                                minval = -1, maxval = 1),
                                name = &#39;mu&#39;)
        self.cdf_layer = cdf_layer()       
        
    def initialize(self, mu, pi):
        # Initialize parameters of the latent space
        if mu is not None:
            self.mu.assign(mu)
        if pi is not None:
            self.pi.assign(pi)

    def normalize(self):
        self.pi = tf.nn.softmax(self.pi)

    @tf.function
    def _get_normal_params(self, z):
        batch_size = tf.shape(z)[0]
        L = tf.shape(z)[1]
        
        # [batch_size, L, n_states]
        temp_pi = tf.tile(
            tf.expand_dims(tf.nn.softmax(self.pi), 1),
            (batch_size,L,1))
                        
        # [batch_size, L, d, n_states]
        a1 = tf.expand_dims(tf.expand_dims(
            tf.gather(self.mu, self.B, axis=1) - tf.gather(self.mu, self.A, axis=1), 0), 0)
        a2 = tf.expand_dims(z,-1) - \
            tf.expand_dims(tf.expand_dims(
            tf.gather(self.mu, self.B, axis=1), 0), 0)
            
        # [batch_size, L, n_states]
        _inv_sig = tf.reduce_sum(a1 * a1, axis=2)
        _mu = - tf.reduce_sum(a1 * a2, axis=2)*tf.math.reciprocal_no_nan(_inv_sig)
        _t = - tf.reduce_sum(a2 * a2, axis=2) + _mu**2*_inv_sig
        return temp_pi, a2, _inv_sig, _mu, _t
    
    @tf.function
    def _get_pz(self, temp_pi, _inv_sig, a2, log_p_z_c_L):
        # [batch_size, L, n_states]
        log_p_zc_L = - 0.5 * self.dim_latent * tf.math.log(2 * np.pi) + \
            tf.math.log(temp_pi+1e-12) + \
            tf.where(_inv_sig==0, 
                    - 0.5 * tf.reduce_sum(a2**2, axis=2), 
                    log_p_z_c_L)
        
        # [batch_size, L, 1]
        log_p_z_L = tf.reduce_logsumexp(log_p_zc_L, axis=-1, keepdims=True)
        
        # [1, ]
        log_p_z = tf.reduce_mean(log_p_z_L)
        return log_p_zc_L, log_p_z_L, log_p_z
    
    @tf.function
    def _get_posterior_c(self, log_p_zc_L, log_p_z_L):
        L = tf.shape(log_p_z_L)[1]

        # log_p_c_x     -   predicted probability distribution
        # [batch_size, n_states]
        log_p_c_x = tf.reduce_logsumexp(
                        log_p_zc_L - log_p_z_L,
                    axis=1) - tf.math.log(tf.cast(L, tf.float32))
        return log_p_c_x

    @tf.function
    def _get_inference(self, z, log_p_zc_L, log_p_z_L):
        batch_size = tf.shape(z)[0]
        L = tf.shape(z)[1]
        
        # [batch_size, L, dim_latent, n_states, M]
        temp_Z = tf.tile(tf.expand_dims(tf.expand_dims(z,-1), -1),
                    (1,1,1,self.n_states,self.M))
        temp_mu = tf.tile(
                        tf.expand_dims(tf.expand_dims(
                            tf.gather(self.mu, self.A, axis=1),0),-1),
                        (batch_size,1,1,self.M)) * self.w + \
                tf.tile(
                        tf.expand_dims(tf.expand_dims(
                            tf.gather(self.mu, self.B, axis=1),0),-1),
                        (batch_size,1,1,self.M)) * (1-self.w)
        temp_mu = tf.tile(tf.expand_dims(temp_mu, 1), (1,L,1,1,1))
            
        # [batch_size, L, n_states, M]
        temp_pi = tf.tile(tf.expand_dims(
                        tf.expand_dims(tf.nn.softmax(self.pi), -1), 1),
                        (batch_size,L,1,self.M))
        
        # [batch_size, L, n_states, M]
        log_p_zc_w = - 0.5 * self.dim_latent * tf.math.log(2 * np.pi) + \
                        tf.math.log(temp_pi+1e-12) - \
                        tf.reduce_sum(tf.math.square(temp_Z - temp_mu), 2)/2  # this omits a term -logM for avoiding numerical issue
                        
        # [batch_size, L]
        log_p_z_L = tf.expand_dims(tf.reduce_logsumexp(log_p_zc_w, axis=[2,3]), -1) # this omits a term -logM for avoiding numerical issue
                    
        # [batch_size, n_states, M]
        p_wc_x = tf.exp(tf.reduce_logsumexp(
                    log_p_zc_w -
                    tf.expand_dims(log_p_z_L, -1),
                    1) - tf.math.log(tf.cast(L, tf.float32)))
                    
        # [batch_size, n_states, n_clusters, M]
        _w = tf.tile(tf.expand_dims(
                tf.tile(tf.expand_dims(
                    tf.one_hot(self.A, self.n_clusters),
                    -1), (1,1,self.M)) * self.w +
                tf.tile(tf.expand_dims(
                    tf.one_hot(self.B, self.n_clusters),
                    -1), (1,1,self.M)) * (1-self.w), 0), (batch_size,1,1,1))
                    
        # [batch_size, n_clusters]
        w_tilde = tf.reduce_sum(
            _w  * \
            tf.tile(tf.expand_dims(p_wc_x, 2), (1,1,self.n_clusters,1)),
            (1,3))
            
        var_w_tilde = tf.reduce_sum(
            tf.math.square(_w)  *
            tf.tile(tf.expand_dims(p_wc_x, 2), (1,1,self.n_clusters,1)),
            (1,3)) - tf.square(w_tilde)    
        
        _wtilde = tf.expand_dims(tf.expand_dims(w_tilde, 1), -1)
        D_JS = tf.reduce_sum(
            tf.math.sqrt(
                0.5 * tf.reduce_mean(
                    _w * tf.math.log(
                        _w/(0.5 * (_w + _wtilde) + 1e-12) + 1e-12) +
                    _wtilde * tf.math.log(
                        _wtilde/(0.5 * (_w + _wtilde) + 1e-12) + 1e-12),
                    axis=2)) * \
            p_wc_x, (1,2)) / tf.cast(self.M, tf.float32)
        return w_tilde, var_w_tilde, D_JS
    
    def get_pz(self, z):
        temp_pi, a2, _inv_sig, _mu, _t = self._get_normal_params(z)
        
        log_p_z_c_L =  0.5 * (tf.math.log(2 * np.pi) - \
                        tf.math.log(_inv_sig+1e-12) + \
                        _t
                        ) + \
                        tf.math.log(self.cdf_layer((1-_mu)*tf.math.sqrt(_inv_sig+1e-12)) - 
                                    self.cdf_layer(-_mu*tf.math.sqrt(_inv_sig+1e-12)) + 1e-12)
        
        log_p_zc_L, log_p_z_L, log_p_z = self._get_pz(temp_pi, _inv_sig, a2, log_p_z_c_L)
        return log_p_zc_L, log_p_z_L, log_p_z

    def call(self, z, inference=False):
        &#39;&#39;&#39;
        Input :
                z       - latent variables outputed by the encoder
                          [batch_size, L, dim_latent]
        Output:       
            inference = True:     
                log_p_z - MC samples for log p(z)=log sum_{c}p(z|c)*p(c)
                          [batch_size, ]
            inference = False:
                res     - results contains estimations for 
                            p(c|x), E(w|x), Var(w|x), E(w|x,c), Var(w|x,c), 
                            c, E(w_tilde), Var(w_tilde), D_JS
        &#39;&#39;&#39;               
        log_p_zc_L, log_p_z_L, log_p_z = self.get_pz(z)

        if not inference:
            return log_p_z
        else:
            log_p_c_x = self._get_posterior_c(log_p_zc_L, log_p_z_L)
            w_tilde, var_w_tilde, D_JS = self._get_inference(z, log_p_zc_L, log_p_z_L)
            
            res = {}
            res[&#39;p_c_x&#39;] = tf.exp(log_p_c_x).numpy()
            res[&#39;w_tilde&#39;] = w_tilde.numpy()
            res[&#39;var_w_tilde&#39;] = var_w_tilde.numpy()
            res[&#39;D_JS&#39;] = D_JS.numpy()
            return res

    def get_posterior_c(self, z):
        log_p_zc_L, log_p_z_L, _ = self.get_pz(z)
        log_p_c_x = self._get_posterior_c(log_p_zc_L, log_p_z_L)
        p_c_x = tf.exp(log_p_c_x).numpy()
        return p_c_x

    def get_proj_z(self, c):
        &#39;&#39;&#39;
        Args:
            c - Numpy array of indexes [1,*]
        &#39;&#39;&#39;
        proj_c = np.tile(c, (self.M,1)).T.flatten()
        proj_z_M = tf.transpose(
                        tf.gather(self.mu, tf.gather(self.A, proj_c), axis=1) * 
                        tf.tile(self.w, (1,len(c))) + 
                        tf.gather(self.mu, tf.gather(self.B, proj_c), axis=1) * 
                        (1-tf.tile(self.w, (1,len(c))))
                    )
        return proj_c, proj_z_M.numpy()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="VITAE.model.LatentSpace.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, mu, pi)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, mu, pi):
    # Initialize parameters of the latent space
    if mu is not None:
        self.mu.assign(mu)
    if pi is not None:
        self.pi.assign(pi)</code></pre>
</details>
</dd>
<dt id="VITAE.model.LatentSpace.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize(self):
    self.pi = tf.nn.softmax(self.pi)</code></pre>
</details>
</dd>
<dt id="VITAE.model.LatentSpace.get_pz"><code class="name flex">
<span>def <span class="ident">get_pz</span></span>(<span>self, z)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pz(self, z):
    temp_pi, a2, _inv_sig, _mu, _t = self._get_normal_params(z)
    
    log_p_z_c_L =  0.5 * (tf.math.log(2 * np.pi) - \
                    tf.math.log(_inv_sig+1e-12) + \
                    _t
                    ) + \
                    tf.math.log(self.cdf_layer((1-_mu)*tf.math.sqrt(_inv_sig+1e-12)) - 
                                self.cdf_layer(-_mu*tf.math.sqrt(_inv_sig+1e-12)) + 1e-12)
    
    log_p_zc_L, log_p_z_L, log_p_z = self._get_pz(temp_pi, _inv_sig, a2, log_p_z_c_L)
    return log_p_zc_L, log_p_z_L, log_p_z</code></pre>
</details>
</dd>
<dt id="VITAE.model.LatentSpace.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, z, inference=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Input :
z
- latent variables outputed by the encoder
[batch_size, L, dim_latent]
Output:
<br>
inference = True:
<br>
log_p_z - MC samples for log p(z)=log sum_{c}p(z|c)*p(c)
[batch_size, ]
inference = False:
res
- results contains estimations for
p(c|x), E(w|x), Var(w|x), E(w|x,c), Var(w|x,c),
c, E(w_tilde), Var(w_tilde), D_JS</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def call(self, z, inference=False):
    &#39;&#39;&#39;
    Input :
            z       - latent variables outputed by the encoder
                      [batch_size, L, dim_latent]
    Output:       
        inference = True:     
            log_p_z - MC samples for log p(z)=log sum_{c}p(z|c)*p(c)
                      [batch_size, ]
        inference = False:
            res     - results contains estimations for 
                        p(c|x), E(w|x), Var(w|x), E(w|x,c), Var(w|x,c), 
                        c, E(w_tilde), Var(w_tilde), D_JS
    &#39;&#39;&#39;               
    log_p_zc_L, log_p_z_L, log_p_z = self.get_pz(z)

    if not inference:
        return log_p_z
    else:
        log_p_c_x = self._get_posterior_c(log_p_zc_L, log_p_z_L)
        w_tilde, var_w_tilde, D_JS = self._get_inference(z, log_p_zc_L, log_p_z_L)
        
        res = {}
        res[&#39;p_c_x&#39;] = tf.exp(log_p_c_x).numpy()
        res[&#39;w_tilde&#39;] = w_tilde.numpy()
        res[&#39;var_w_tilde&#39;] = var_w_tilde.numpy()
        res[&#39;D_JS&#39;] = D_JS.numpy()
        return res</code></pre>
</details>
</dd>
<dt id="VITAE.model.LatentSpace.get_posterior_c"><code class="name flex">
<span>def <span class="ident">get_posterior_c</span></span>(<span>self, z)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_posterior_c(self, z):
    log_p_zc_L, log_p_z_L, _ = self.get_pz(z)
    log_p_c_x = self._get_posterior_c(log_p_zc_L, log_p_z_L)
    p_c_x = tf.exp(log_p_c_x).numpy()
    return p_c_x</code></pre>
</details>
</dd>
<dt id="VITAE.model.LatentSpace.get_proj_z"><code class="name flex">
<span>def <span class="ident">get_proj_z</span></span>(<span>self, c)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>c - Numpy array of indexes [1,*]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_proj_z(self, c):
    &#39;&#39;&#39;
    Args:
        c - Numpy array of indexes [1,*]
    &#39;&#39;&#39;
    proj_c = np.tile(c, (self.M,1)).T.flatten()
    proj_z_M = tf.transpose(
                    tf.gather(self.mu, tf.gather(self.A, proj_c), axis=1) * 
                    tf.tile(self.w, (1,len(c))) + 
                    tf.gather(self.mu, tf.gather(self.B, proj_c), axis=1) * 
                    (1-tf.tile(self.w, (1,len(c))))
                )
    return proj_c, proj_z_M.numpy()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder"><code class="flex name class">
<span>class <span class="ident">VariationalAutoEncoder</span></span>
<span>(</span><span>dim_origin, dimensions, dim_latent, data_type='UMI', has_cov=False, name='autoencoder', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Combines the encoder, decoder and LatentSpace into an end-to-end model for training.</p>
<h2 id="args">Args</h2>
<p>n_clusters
-
Number of clusters.
dim_origin
-
Dim of input.
dimensions
-
List of dimensions of layers of the encoder. Assume
symmetric network sturcture of encoder and decoder.
dim_latent
-
Dimension of latent layer.
data_type
-
Type of count data.
'UMI' for negative binomial loss;
'non-UMI' for zero-inflated negative binomial loss.
has_cov
- has covariate or not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VariationalAutoEncoder(tf.keras.Model):
    &#34;&#34;&#34;
    Combines the encoder, decoder and LatentSpace into an end-to-end model for training.
    &#34;&#34;&#34;
    def __init__(self, dim_origin, dimensions, dim_latent,
                 data_type = &#39;UMI&#39;, has_cov=False,
                 name = &#39;autoencoder&#39;, **kwargs):
        &#39;&#39;&#39;
        Args:
            n_clusters      -   Number of clusters.
            dim_origin      -   Dim of input.
            dimensions      -   List of dimensions of layers of the encoder. Assume
                               symmetric network sturcture of encoder and decoder.
            dim_latent      -   Dimension of latent layer.
            data_type       -   Type of count data.
                              &#39;UMI&#39; for negative binomial loss;
                              &#39;non-UMI&#39; for zero-inflated negative binomial loss.
            has_cov         - has covariate or not
        &#39;&#39;&#39;
        super(VariationalAutoEncoder, self).__init__(name = name, **kwargs)
        self.data_type = data_type
        self.dim_origin = dim_origin
        self.dim_latent = dim_latent
        self.encoder = Encoder(dimensions, dim_latent)
        self.decoder = Decoder(dimensions[::-1], dim_origin, data_type, data_type)        
        self.has_cov = has_cov
        
    def init_latent_space(self, n_clusters, mu, pi=None):
        self.n_clusters = n_clusters
        self.latent_space = LatentSpace(self.n_clusters, self.dim_latent)
        self.latent_space.initialize(mu, pi)

    def call(self, x_normalized, c_score, x = None, scale_factor = 1,
             pre_train = False, L=1, alpha=0.0):
        # Feed forward through encoder, LatentSpace layer and decoder.
        if not pre_train and self.latent_space is None:
            raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
                    
        x_normalized = tf.concat([x_normalized, c_score], -1) if self.has_cov else x_normalized
        _, z_log_var, z = self.encoder(x_normalized, L)
                
        z_in = tf.concat([z, tf.tile(tf.expand_dims(c_score,1), (1,L,1))], -1) if self.has_cov else z
        
        x = tf.tile(tf.expand_dims(x, 1), (1,L,1))
        reconstruction_z_loss = self.get_reconstruction_loss(x, z_in, scale_factor, L)
        
        if self.has_cov and alpha&gt;0.0:
            zero_in = tf.concat([tf.zeros([z.shape[0],1,z.shape[2]]), tf.tile(tf.expand_dims(c_score,1), (1,1,1))], -1)
            reconstruction_zero_loss = self.get_reconstruction_loss(x, zero_in, scale_factor, 1)
            reconstruction_z_loss = (1-alpha)*reconstruction_z_loss + alpha*reconstruction_zero_loss
        
        self.add_loss(reconstruction_z_loss)

        if not pre_train:        
            log_p_z = self.latent_space(z, inference=False)

            # - E_q[log p(z)]
            self.add_loss(- log_p_z)

            # - Eq[log q(z|x)]
            E_qzx = - tf.reduce_mean(
                            0.5 * self.dim_latent *
                            (tf.math.log(2 * np.pi) + 1) +
                            0.5 * tf.reduce_sum(z_log_var, axis=-1)
                            )
            self.add_loss(E_qzx)
        return self.losses
    
    @tf.function
    def get_reconstruction_loss(self, x, z_in, scale_factor, L):
        if self.data_type==&#39;Gaussian&#39;:
            # Gaussian Log-Likelihood Loss function
            nu_z, tau = self.decoder(z_in)
            neg_E_Gaus = 0.5 * tf.math.log(tau + 1e-12) + 0.5 * tf.math.square(x - nu_z) / tau
            neg_E_Gaus = tf.reduce_mean(tf.reduce_sum(neg_E_Gaus, axis=-1))
            
            return neg_E_Gaus
        else:
            if self.data_type == &#39;UMI&#39;:
                x_hat, r = self.decoder(z_in)
            else:
                x_hat, r, phi = self.decoder(z_in)

            x_hat = x_hat*tf.expand_dims(scale_factor, -1)

            # Negative Log-Likelihood Loss function

            # Ref for NB &amp; ZINB loss functions:
            # https://github.com/gokceneraslan/neuralnet_countmodels/blob/master/Count%20models%20with%20neuralnets.ipynb
            # Negative Binomial loss

            neg_E_nb = tf.math.lgamma(r) + tf.math.lgamma(x+1.0) \
                        - tf.math.lgamma(x+r) + \
                        (r+x) * tf.math.log(1.0 + (x_hat/r)) + \
                        x * (tf.math.log(r) - tf.math.log(x_hat+1e-12))
            
            if self.data_type == &#39;non-UMI&#39;:
                # Zero-Inflated Negative Binomial loss
                nb_case = neg_E_nb - tf.math.log(1.0-phi+1e-12)
                zero_case = - tf.math.log(phi + (1.0-phi) *
                                     tf.pow(r/(r + x_hat + 1e-12), r) + 1e-12)
                neg_E_nb = tf.where(tf.less(x, 1e-8), zero_case, nb_case)

            neg_E_nb =  tf.reduce_mean(tf.reduce_sum(neg_E_nb, axis=-1))
            
            return neg_E_nb
    
    def get_z(self, x_normalized, c_score):        
        x_normalized = x_normalized if (not self.has_cov or c_score is None) else tf.concat([x_normalized, c_score], -1)
        z_mean, _, _ = self.encoder(x_normalized, 1, False)
        return z_mean.numpy()
    
    def get_proj_z(self, c):
        &#39;&#39;&#39;
        Args:
            c - List of indexes of edges
        &#39;&#39;&#39;
        return self.latent_space.get_proj_z(c)

    def get_pc_x(self, test_dataset):
        if self.latent_space is None:
            raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
        
        pi_norm = tf.nn.softmax(self.latent_space.pi).numpy()
        p_c_x = []
        for x,c_score in test_dataset:
            x = tf.concat([x, c_score], -1) if self.has_cov else x
            _, _, z = self.encoder(x, 1, False)
            _p_c_x = self.latent_space.get_posterior_c(z)            
            p_c_x.append(_p_c_x)
        p_c_x = np.concatenate(p_c_x)         
        return pi_norm, p_c_x

    def inference(self, test_dataset, L=1):
        if self.latent_space is None:
            raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
            
        pi_norm = tf.nn.softmax(self.latent_space.pi).numpy()
        mu = self.latent_space.mu.numpy()
        z_mean = []
        p_c_x = []
        w_tilde = []
        var_w_tilde = []
        D_JS = []
        for x,c_score in test_dataset:
            x = tf.concat([x, c_score], -1) if self.has_cov else x
            _z_mean, _, z = self.encoder(x, L, False)
            res = self.latent_space(z, inference=True)
            
            z_mean.append(_z_mean.numpy())
            p_c_x.append(res[&#39;p_c_x&#39;])            
            w_tilde.append(res[&#39;w_tilde&#39;])
            var_w_tilde.append(res[&#39;var_w_tilde&#39;])
            D_JS.append(res[&#39;D_JS&#39;])
        
        D_JS = np.concatenate(D_JS)
        z_mean = np.concatenate(z_mean)
        p_c_x = np.concatenate(p_c_x)
        w_tilde = np.concatenate(w_tilde)
        var_w_tilde = np.concatenate(var_w_tilde)
        return pi_norm, mu, p_c_x, w_tilde, var_w_tilde, D_JS, z_mean</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.engine.training.Model</li>
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
<li>tensorflow.python.keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="VITAE.model.VariationalAutoEncoder.init_latent_space"><code class="name flex">
<span>def <span class="ident">init_latent_space</span></span>(<span>self, n_clusters, mu, pi=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_latent_space(self, n_clusters, mu, pi=None):
    self.n_clusters = n_clusters
    self.latent_space = LatentSpace(self.n_clusters, self.dim_latent)
    self.latent_space.initialize(mu, pi)</code></pre>
</details>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, x_normalized, c_score, x=None, scale_factor=1, pre_train=False, L=1, alpha=0.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls the model on new inputs.</p>
<p>In this case <code>call</code> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<h2 id="arguments">Arguments</h2>
<p>inputs: A tensor or list of tensors.
training: Boolean or boolean scalar tensor, indicating whether to run
the <code>Network</code> in training mode or inference mode.
mask: A mask or list of masks. A mask can be
either a tensor or None (no mask).</p>
<h2 id="returns">Returns</h2>
<p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def call(self, x_normalized, c_score, x = None, scale_factor = 1,
         pre_train = False, L=1, alpha=0.0):
    # Feed forward through encoder, LatentSpace layer and decoder.
    if not pre_train and self.latent_space is None:
        raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
                
    x_normalized = tf.concat([x_normalized, c_score], -1) if self.has_cov else x_normalized
    _, z_log_var, z = self.encoder(x_normalized, L)
            
    z_in = tf.concat([z, tf.tile(tf.expand_dims(c_score,1), (1,L,1))], -1) if self.has_cov else z
    
    x = tf.tile(tf.expand_dims(x, 1), (1,L,1))
    reconstruction_z_loss = self.get_reconstruction_loss(x, z_in, scale_factor, L)
    
    if self.has_cov and alpha&gt;0.0:
        zero_in = tf.concat([tf.zeros([z.shape[0],1,z.shape[2]]), tf.tile(tf.expand_dims(c_score,1), (1,1,1))], -1)
        reconstruction_zero_loss = self.get_reconstruction_loss(x, zero_in, scale_factor, 1)
        reconstruction_z_loss = (1-alpha)*reconstruction_z_loss + alpha*reconstruction_zero_loss
    
    self.add_loss(reconstruction_z_loss)

    if not pre_train:        
        log_p_z = self.latent_space(z, inference=False)

        # - E_q[log p(z)]
        self.add_loss(- log_p_z)

        # - Eq[log q(z|x)]
        E_qzx = - tf.reduce_mean(
                        0.5 * self.dim_latent *
                        (tf.math.log(2 * np.pi) + 1) +
                        0.5 * tf.reduce_sum(z_log_var, axis=-1)
                        )
        self.add_loss(E_qzx)
    return self.losses</code></pre>
</details>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder.get_reconstruction_loss"><code class="name flex">
<span>def <span class="ident">get_reconstruction_loss</span></span>(<span>self, x, z_in, scale_factor, L)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.function
def get_reconstruction_loss(self, x, z_in, scale_factor, L):
    if self.data_type==&#39;Gaussian&#39;:
        # Gaussian Log-Likelihood Loss function
        nu_z, tau = self.decoder(z_in)
        neg_E_Gaus = 0.5 * tf.math.log(tau + 1e-12) + 0.5 * tf.math.square(x - nu_z) / tau
        neg_E_Gaus = tf.reduce_mean(tf.reduce_sum(neg_E_Gaus, axis=-1))
        
        return neg_E_Gaus
    else:
        if self.data_type == &#39;UMI&#39;:
            x_hat, r = self.decoder(z_in)
        else:
            x_hat, r, phi = self.decoder(z_in)

        x_hat = x_hat*tf.expand_dims(scale_factor, -1)

        # Negative Log-Likelihood Loss function

        # Ref for NB &amp; ZINB loss functions:
        # https://github.com/gokceneraslan/neuralnet_countmodels/blob/master/Count%20models%20with%20neuralnets.ipynb
        # Negative Binomial loss

        neg_E_nb = tf.math.lgamma(r) + tf.math.lgamma(x+1.0) \
                    - tf.math.lgamma(x+r) + \
                    (r+x) * tf.math.log(1.0 + (x_hat/r)) + \
                    x * (tf.math.log(r) - tf.math.log(x_hat+1e-12))
        
        if self.data_type == &#39;non-UMI&#39;:
            # Zero-Inflated Negative Binomial loss
            nb_case = neg_E_nb - tf.math.log(1.0-phi+1e-12)
            zero_case = - tf.math.log(phi + (1.0-phi) *
                                 tf.pow(r/(r + x_hat + 1e-12), r) + 1e-12)
            neg_E_nb = tf.where(tf.less(x, 1e-8), zero_case, nb_case)

        neg_E_nb =  tf.reduce_mean(tf.reduce_sum(neg_E_nb, axis=-1))
        
        return neg_E_nb</code></pre>
</details>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder.get_z"><code class="name flex">
<span>def <span class="ident">get_z</span></span>(<span>self, x_normalized, c_score)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_z(self, x_normalized, c_score):        
    x_normalized = x_normalized if (not self.has_cov or c_score is None) else tf.concat([x_normalized, c_score], -1)
    z_mean, _, _ = self.encoder(x_normalized, 1, False)
    return z_mean.numpy()</code></pre>
</details>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder.get_proj_z"><code class="name flex">
<span>def <span class="ident">get_proj_z</span></span>(<span>self, c)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>c - List of indexes of edges</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_proj_z(self, c):
    &#39;&#39;&#39;
    Args:
        c - List of indexes of edges
    &#39;&#39;&#39;
    return self.latent_space.get_proj_z(c)</code></pre>
</details>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder.get_pc_x"><code class="name flex">
<span>def <span class="ident">get_pc_x</span></span>(<span>self, test_dataset)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pc_x(self, test_dataset):
    if self.latent_space is None:
        raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
    
    pi_norm = tf.nn.softmax(self.latent_space.pi).numpy()
    p_c_x = []
    for x,c_score in test_dataset:
        x = tf.concat([x, c_score], -1) if self.has_cov else x
        _, _, z = self.encoder(x, 1, False)
        _p_c_x = self.latent_space.get_posterior_c(z)            
        p_c_x.append(_p_c_x)
    p_c_x = np.concatenate(p_c_x)         
    return pi_norm, p_c_x</code></pre>
</details>
</dd>
<dt id="VITAE.model.VariationalAutoEncoder.inference"><code class="name flex">
<span>def <span class="ident">inference</span></span>(<span>self, test_dataset, L=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inference(self, test_dataset, L=1):
    if self.latent_space is None:
        raise ReferenceError(&#39;Have not initialized the latent space.&#39;)
        
    pi_norm = tf.nn.softmax(self.latent_space.pi).numpy()
    mu = self.latent_space.mu.numpy()
    z_mean = []
    p_c_x = []
    w_tilde = []
    var_w_tilde = []
    D_JS = []
    for x,c_score in test_dataset:
        x = tf.concat([x, c_score], -1) if self.has_cov else x
        _z_mean, _, z = self.encoder(x, L, False)
        res = self.latent_space(z, inference=True)
        
        z_mean.append(_z_mean.numpy())
        p_c_x.append(res[&#39;p_c_x&#39;])            
        w_tilde.append(res[&#39;w_tilde&#39;])
        var_w_tilde.append(res[&#39;var_w_tilde&#39;])
        D_JS.append(res[&#39;D_JS&#39;])
    
    D_JS = np.concatenate(D_JS)
    z_mean = np.concatenate(z_mean)
    p_c_x = np.concatenate(p_c_x)
    w_tilde = np.concatenate(w_tilde)
    var_w_tilde = np.concatenate(var_w_tilde)
    return pi_norm, mu, p_c_x, w_tilde, var_w_tilde, D_JS, z_mean</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="VITAE" href="index.html">VITAE</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="VITAE.model.cdf_layer" href="#VITAE.model.cdf_layer">cdf_layer</a></code></h4>
<ul class="">
<li><code><a title="VITAE.model.cdf_layer.call" href="#VITAE.model.cdf_layer.call">call</a></code></li>
<li><code><a title="VITAE.model.cdf_layer.func" href="#VITAE.model.cdf_layer.func">func</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="VITAE.model.Sampling" href="#VITAE.model.Sampling">Sampling</a></code></h4>
<ul class="">
<li><code><a title="VITAE.model.Sampling.call" href="#VITAE.model.Sampling.call">call</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="VITAE.model.Encoder" href="#VITAE.model.Encoder">Encoder</a></code></h4>
<ul class="">
<li><code><a title="VITAE.model.Encoder.call" href="#VITAE.model.Encoder.call">call</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="VITAE.model.Decoder" href="#VITAE.model.Decoder">Decoder</a></code></h4>
<ul class="">
<li><code><a title="VITAE.model.Decoder.call" href="#VITAE.model.Decoder.call">call</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="VITAE.model.LatentSpace" href="#VITAE.model.LatentSpace">LatentSpace</a></code></h4>
<ul class="two-column">
<li><code><a title="VITAE.model.LatentSpace.initialize" href="#VITAE.model.LatentSpace.initialize">initialize</a></code></li>
<li><code><a title="VITAE.model.LatentSpace.normalize" href="#VITAE.model.LatentSpace.normalize">normalize</a></code></li>
<li><code><a title="VITAE.model.LatentSpace.get_pz" href="#VITAE.model.LatentSpace.get_pz">get_pz</a></code></li>
<li><code><a title="VITAE.model.LatentSpace.call" href="#VITAE.model.LatentSpace.call">call</a></code></li>
<li><code><a title="VITAE.model.LatentSpace.get_posterior_c" href="#VITAE.model.LatentSpace.get_posterior_c">get_posterior_c</a></code></li>
<li><code><a title="VITAE.model.LatentSpace.get_proj_z" href="#VITAE.model.LatentSpace.get_proj_z">get_proj_z</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="VITAE.model.VariationalAutoEncoder" href="#VITAE.model.VariationalAutoEncoder">VariationalAutoEncoder</a></code></h4>
<ul class="">
<li><code><a title="VITAE.model.VariationalAutoEncoder.init_latent_space" href="#VITAE.model.VariationalAutoEncoder.init_latent_space">init_latent_space</a></code></li>
<li><code><a title="VITAE.model.VariationalAutoEncoder.call" href="#VITAE.model.VariationalAutoEncoder.call">call</a></code></li>
<li><code><a title="VITAE.model.VariationalAutoEncoder.get_reconstruction_loss" href="#VITAE.model.VariationalAutoEncoder.get_reconstruction_loss">get_reconstruction_loss</a></code></li>
<li><code><a title="VITAE.model.VariationalAutoEncoder.get_z" href="#VITAE.model.VariationalAutoEncoder.get_z">get_z</a></code></li>
<li><code><a title="VITAE.model.VariationalAutoEncoder.get_proj_z" href="#VITAE.model.VariationalAutoEncoder.get_proj_z">get_proj_z</a></code></li>
<li><code><a title="VITAE.model.VariationalAutoEncoder.get_pc_x" href="#VITAE.model.VariationalAutoEncoder.get_pc_x">get_pc_x</a></code></li>
<li><code><a title="VITAE.model.VariationalAutoEncoder.inference" href="#VITAE.model.VariationalAutoEncoder.inference">inference</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>